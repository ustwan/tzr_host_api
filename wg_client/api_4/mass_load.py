#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –º–∞—Å—Å–æ–≤–æ–π –∑–∞–≥—Ä—É–∑–∫–∏ TZB —Ñ–∞–π–ª–æ–≤ —Å –¥–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏–µ–π –∏ —Å–∂–∞—Ç–∏–µ–º
"""
import asyncio
import os
import sys
import gzip
import shutil
from pathlib import Path
from typing import List, Dict, Any

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –º–æ–¥—É–ª—è–º
sys.path.append('/app')

from app.database import BattleDatabase
from app.loader import BattleLoader
from app.parser import BattleParser


class MassLoader:
    def __init__(self, source_dir: str, target_dir: str = "/srv/btl_mirror"):
        self.source_dir = Path(source_dir)
        self.target_dir = Path(target_dir)
        self.db = BattleDatabase()
        self.parser = BattleParser()
        self.loader = BattleLoader(self.db, self.parser)
        
    async def dedupe_and_compress(self, file_path: Path) -> Path:
        """–î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Å–∂–∞—Ç–∏–µ —Ñ–∞–π–ª–∞"""
        # –ß–∏—Ç–∞–µ–º —Ñ–∞–π–ª
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è (—É–¥–∞–ª—è–µ–º –¥—É–±–ª–∏—Ä—É—é—â–∏–µ—Å—è <BATTLE> –±–ª–æ–∫–∏)
        from app.external_parser import dedupe_tzb_content
        deduped_content = dedupe_tzb_content(content)
        
        # –°–æ–∑–¥–∞–µ–º —Å–∂–∞—Ç—ã–π —Ñ–∞–π–ª
        compressed_path = self.target_dir / f"{file_path.stem}.tzb.gz"
        with gzip.open(compressed_path, 'wt', encoding='utf-8') as f:
            f.write(deduped_content)
        
        return compressed_path
    
    async def process_batch(self, files: List[Path], batch_size: int = 10) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ —Ñ–∞–π–ª–æ–≤"""
        results = {
            'total_files': len(files),
            'processed': 0,
            'successful': 0,
            'failed': 0,
            'errors': []
        }
        
        # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        self.target_dir.mkdir(parents=True, exist_ok=True)
        
        for i in range(0, len(files), batch_size):
            batch = files[i:i + batch_size]
            print(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é –±–∞—Ç—á {i//batch_size + 1}: —Ñ–∞–π–ª—ã {i+1}-{min(i+batch_size, len(files))}")
            
            for file_path in batch:
                try:
                    # –î–µ–¥—É–ø–ª–∏–∫–∞—Ü–∏—è –∏ —Å–∂–∞—Ç–∏–µ
                    compressed_path = await self.dedupe_and_compress(file_path)
                    
                    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤ –±–∞–∑—É
                    result = await self.loader.process_file(str(compressed_path))
                    
                    results['processed'] += 1
                    if result.get('status') == 'success':
                        results['successful'] += 1
                        print(f"‚úÖ {file_path.name} -> {compressed_path.name}")
                    else:
                        results['failed'] += 1
                        error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path.name}: {result.get('error', 'Unknown error')}"
                        results['errors'].append(error_msg)
                        print(f"‚ùå {file_path.name}: {error_msg}")
                    
                except Exception as e:
                    results['failed'] += 1
                    error_msg = f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {file_path.name}: {str(e)}"
                    results['errors'].append(error_msg)
                    print(f"‚ùå {file_path.name}: {error_msg}")
        
        return results
    
    async def load_mass_data(self, limit: int = 1000) -> Dict[str, Any]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –±–æ–ª—å—à–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ñ–∞–π–ª–æ–≤"""
        print(f"üöÄ –ù–∞—á–∏–Ω–∞—é –º–∞—Å—Å–æ–≤—É—é –∑–∞–≥—Ä—É–∑–∫—É –¥–æ {limit} —Ñ–∞–π–ª–æ–≤...")
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ TZB —Ñ–∞–π–ª—ã
        tzb_files = list(self.source_dir.rglob('*.tzb'))[:limit]
        print(f"üìÅ –ù–∞–π–¥–µ–Ω–æ {len(tzb_files)} TZB —Ñ–∞–π–ª–æ–≤")
        
        if not tzb_files:
            print("‚ùå TZB —Ñ–∞–π–ª—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
            return {'error': 'No TZB files found'}
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –±–∞—Ç—á–∞–º–∏
        results = await self.process_batch(tzb_files, batch_size=10)
        
        print(f"\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∑–∞–≥—Ä—É–∑–∫–∏:")
        print(f"   –í—Å–µ–≥–æ —Ñ–∞–π–ª–æ–≤: {results['total_files']}")
        print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {results['processed']}")
        print(f"   –£—Å–ø–µ—à–Ω–æ: {results['successful']}")
        print(f"   –û—à–∏–±–æ–∫: {results['failed']}")
        
        if results['errors']:
            print(f"\n‚ùå –û—à–∏–±–∫–∏:")
            for error in results['errors'][:5]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –æ—à–∏–±–æ–∫
                print(f"   {error}")
            if len(results['errors']) > 5:
                print(f"   ... –∏ –µ—â–µ {len(results['errors']) - 5} –æ—à–∏–±–æ–∫")
        
        return results
    
    async def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        await self.db.disconnect()


async def main():
    if len(sys.argv) < 2:
        print("Usage: mass_load.py <source_directory> [limit]")
        sys.exit(1)
    
    source_dir = sys.argv[1]
    limit = int(sys.argv[2]) if len(sys.argv) > 2 else 1000
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
    os.environ.setdefault("DB_MODE", "test")
    
    loader = MassLoader(source_dir)
    
    try:
        results = await loader.load_mass_data(limit)
        print(f"\n‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞: {results}")
    except Exception as e:
        print(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)
    finally:
        await loader.cleanup()


if __name__ == "__main__":
    asyncio.run(main())









